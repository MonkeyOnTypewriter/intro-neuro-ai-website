<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/i2course/assets/css/just-the-docs-default.css"> <script src="/i2course/assets/js/vendor/lunr.min.js"></script> <script src="/i2course/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Unit 05 | I2 Intro Neuro/AI</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="Unit 05" /><meta name="author" content="Interactive Intelligence" /><meta property="og:locale" content="en_US" /><meta name="description" content="Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!" /><meta property="og:description" content="Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!" /><link rel="canonical" href="http://localhost:3001/i2course/megadoc/unit-05/" /><meta property="og:url" content="http://localhost:3001/i2course/megadoc/unit-05/" /><meta property="og:site_name" content="I2 Intro Neuro/AI" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Unit 05" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Interactive Intelligence"},"description":"Welcome to Interactive Intelligence’s Introduction to Neuro/AI crash course!","headline":"Unit 05","url":"http://localhost:3001/i2course/megadoc/unit-05/"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="/i2course/" class="site-title lh-tight"> I2 Intro Neuro/AI </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/i2course/announcements/" class="nav-list-link">Announcements</a><li class="nav-list-item active"><a href="#" class="nav-list-expander" aria-label="toggle links in Megadoc category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/i2course/megadoc/" class="nav-list-link">Megadoc</a><ul class="nav-list"><li class="nav-list-item "><a href="/i2course/megadoc/unit-01/" class="nav-list-link">Unit 01</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-02/" class="nav-list-link">Unit 02</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-03/" class="nav-list-link">Unit 03</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-04/" class="nav-list-link">Unit 04</a><li class="nav-list-item active"><a href="/i2course/megadoc/unit-05/" class="nav-list-link active">Unit 05</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-06/" class="nav-list-link">Unit 06</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-07/" class="nav-list-link">Unit 07</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-08/" class="nav-list-link">Unit 08</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-09/" class="nav-list-link">Unit 09</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-10/" class="nav-list-link">Unit 10</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-11/" class="nav-list-link">Unit 11</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-12/" class="nav-list-link">Unit 12</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-A/" class="nav-list-link">Unit A</a><li class="nav-list-item "><a href="/i2course/megadoc/unit-B/" class="nav-list-link">Unit B</a></ul><li class="nav-list-item"><a href="/i2course/schedule/" class="nav-list-link">Schedule</a><li class="nav-list-item"><a href="/i2course/staff/" class="nav-list-link">Staff</a><li class="nav-list-item"><a href="/i2course/wiki/" class="nav-list-link">Wiki</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search I2 Intro Neuro/AI" aria-label="Search I2 Intro Neuro/AI" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://interactive-intelligence.github.io" class="site-button" > Interactive Intelligence </a><li class="aux-nav-list-item"> <a href="https://github.com/interactive-intelligence/intro-neuro-ai" class="site-button" > Course GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="/i2course/megadoc/">Megadoc</a><li class="breadcrumb-nav-list-item"><span>Unit 05</span></ol></nav><div id="main-content" class="main-content" role="main"><h1 id="unit-5-computer-vision"> <a href="#unit-5-computer-vision" class="anchor-heading" aria-labelledby="unit-5-computer-vision"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Unit 5: Computer Vision</h1><p>Hello and welcome to the <em>Computer Vision (CV)</em> section of the I2 megadoc! This section is, due to time constraints, only a very cursory glance at the foundations of CV. This is a whole subfield of ML and even if we spent 10 weeks on it, we wouldn’t scratch the surface!</p><p>Let’s start with some motivation. When you look at an image of (for example) a soda can, it does not matter where in the image the soda can is. You are able to detect it and know where it is. This detection ability is called <em>translational invariance</em>. You are able to detect an object even if it has been translated within an image. Traditional DNNs cannot do this (without being heavily overparameterized). Take a second to think about why the architecture of a DNN does not implicitly allow for translationally invariant object classification.</p><ul><li>(Hint: Think about how different the vectorized images would be between the soda can image and its translated invariant. The inputs to the DNN would be drastically different and it would be hard to find any pattern!)</ul><p>Convolutional Neural Networks (or CNNs) solve this problem and much more. To understand what a CNN is though, you must first understand what a convolution is!</p><p><strong>Task:</strong> Watch and understand the following videos. We recommend taking notes and being able to answer the synthesis questions provided below. Send your I2 teacher/mentor/overlord the answers to the questions over Discord. <strong>Watch up to <span style="text-decoration:underline;">13:42</span> in the video, anything after that is extra information not needed for Deep Learning.</strong></p><p><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=KuXjwB4LzSA&amp;t=773s">But what is a convolution?</a> <strong>(13 min)</strong></p><h3 id="synthesis-questions"> <a href="#synthesis-questions" class="anchor-heading" aria-labelledby="synthesis-questions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">Synthesis Questions:</code></h3><ul><li><code class="language-plaintext highlighter-rouge">What is the name for the smaller grid that convolves over a larger image?</code><ul><li><code class="language-plaintext highlighter-rouge">Hint: Starts with a "k"</code></ul><li><code class="language-plaintext highlighter-rouge">What are some examples of what you can do to images if you convolve them with special matrices?</code><li><code class="language-plaintext highlighter-rouge">How does Gaussian blur "work"?</code><li><code class="language-plaintext highlighter-rouge">What is the name for the actual operation that occurs when the smaller grid is overlaid on the larger one?</code><ul><li><code class="language-plaintext highlighter-rouge">When each element of the corresponding pixels are multiplied then summed.</code></ul><li><code class="language-plaintext highlighter-rouge">Give an example of a 3x3 matrix that would not do anything to the image it convolves over. Why does it not impact the image?</code><ul><li><code class="language-plaintext highlighter-rouge">This is also known as the "do-nothing" matrix</code></ul></ul><p><img src="../assets/image6.gif" alt="alt_text" /></p><p>Awesome job! Now we move onto integrating the concept of a convolution into a neural network.</p><p><strong>Task:</strong> Read the following article, watch the video, and answer the synthesis questions:</p><p><strong>Article:</strong> <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">Comprehensive CNN Guide</a> <strong>(15 min)</strong></p><p><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=JboZfxUjLSk">Visualizing Convolutional Neural Networks | Layer by Layer</a> <strong>(5 min)</strong></p><h3 id="synthesis-questions-1"> <a href="#synthesis-questions-1" class="anchor-heading" aria-labelledby="synthesis-questions-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">Synthesis Questions:</code></h3><ul><li><code class="language-plaintext highlighter-rouge">The architecture of a CNN is loosely based on what part of the brain?</code><li><code class="language-plaintext highlighter-rouge">What is stride length?</code><li><code class="language-plaintext highlighter-rouge">What is padding?</code><ul><li><code class="language-plaintext highlighter-rouge">Why is padding useful?</code></ul><li><code class="language-plaintext highlighter-rouge">What is the objective of the convolutional layer in a CNN?</code><li><code class="language-plaintext highlighter-rouge">What is the purpose of the pooling layer in a CNN?</code><ul><li><code class="language-plaintext highlighter-rouge">What are the two ways to pool shown to you in the article?</code></ul><li><code class="language-plaintext highlighter-rouge">What is flattening and when is it done in a CNN?</code><li><code class="language-plaintext highlighter-rouge">What is the purpose of the feedforward layer in a CNN?</code><li><code class="language-plaintext highlighter-rouge">How do the convolutional layers before the feedforward layer in a CNN allow for higher accuracy?</code></ul><p>We have introduced you to the idea of a convolution and how convolutions are applied in CNNs. Can you begin to see how convolutions help with <em>translational invariance</em>? Think about it for a bit! Before the project, we just want to expose you to a few different types of convolutions. They aren’t all the same and serve different purposes.</p><p><strong>Task:</strong> Read the following article for the following sections:</p><ol><li><strong>Convolution in Deep Learning</strong><li><strong>3D Convolution</strong><li><strong>Transposed Convolution/Deconvolution</strong></ol><p><strong>Article:</strong> <a href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215#:~:text=Convolution%20Arithmetic,Spatially%20Separable%20Convolution%2C%20Depthwise%20Convolution">Comprehensive Convolution Types Guide</a>) <strong>(15 min)</strong></p><p>Awesome job! Feel free to move onto the project now.</p><p>For those of you more interested in CV, there are a bunch more things to do in this sphere. Here are some topics you can explore independently:</p><ul><li><strong>Transfer learning</strong><li><strong>Object detection (r-cnn, yolo)</strong><li><strong>Semantic segmentation (u-net, deeplab)</strong><li><strong>Self-supervised learning (colorization, damage correction, noise decoding)</strong><li><strong>Adversarial attacks</strong><li><strong>Image generation - variational autoencoders, generative adversarial networks</strong></ul><p>Here are some slides from a JC on Variational Autoencoders (somewhat related, but very cool!): <a href="https://docs.google.com/presentation/d/1KTb7wxnsBryuar-yB-AVrizw88Wc3Vue46iCwmN0558/edit?usp=sharing">Variational Autoencoder JC Slides</a></p><p><strong>Project Spec:</strong></p><p>The project for this “<em>Computer Vision</em>” section will be following the tutorial/Jupyter Notebook below. Please ask questions in the discord as you work through this project. Be sure to discuss with others in your group!</p><p>A few helpful tips:</p><ul><li>Use GitHub, it’s really just better<li>Use <a href="https://www.anaconda.com/">Anaconda</a> with <a href="https://www.python.org/downloads/">Python3</a> in <a href="https://code.visualstudio.com/">VSCode</a>.<ul><li>If you use Anaconda, create a separate environment so you can mess with libraries and imports all day without screwing up your base environment.</ul><li>Type most of the code out yourself instead of just copying from the tutorial.<li>Leave comments to cement your understanding. Link syntax to ideas.<li><strong>Read up on what <span style="text-decoration:underline;">Fashion</span>-MNIST is (different than MNIST).</strong></ul><p><strong>Clone the Git repo onto your local device if you have not already.</strong></p><p>Then, in your local copy of the GitHub repo, navigate to the unit-5 folder, and work on <strong>conv-net.ipynb</strong>. Instructions are in the Jupyter notebook. If you need help setting up your python environment, ask the TA’s!</p><p><strong>GH Link:</strong> <a href="https://github.com/interactive-intelligence/intro-neuro-ai/blob/main/unit-05/conv-net.ipynb">Unit 5 Notebook</a>** (1 hr)**</p><p>When you are finished with your code, independently verify that it works and have fun with it! If you add any additional functionality be sure to talk about it with others and give them ideas.</p><p>Remember that this is all for your learning, so do your best and don’t stress!</p><p>Congratulations! You now understand the basics of Convolutional Neural networks!</p></div></div><div class="search-overlay"></div></div>
